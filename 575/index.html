

<!DOCTYPE html>
<html lang="en">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Syllabus</title>

<style>
	body{
		margin:1em auto;
		max-width:40em;
		padding:0 .62em;
		font:1.2em/1.62 sans-serif;
	}
	h1,h2,h3 {
		line-height:1.2;
	}
	@media print{
		body{
			max-width:none
		}
	}
	.venue { font-style: italic; }
	.note { font-style: italic; font-size: x-small; }
</style>

<article>

	<h1>Statistical Models and Methods for Business Analytics</h1>
<h3><center> IDS 575 (Spring 2019) </center></h3>
<p>Document version: Jan 27 2019</p>
<p><span style="color:red">All announcements will be made on the <a href="https://forum.chicagods.com">Forum</a> </span></p>
<h2>Overview</h2>
<p>The goal of this class is to cover the foundations of modern statistics and machine learning complementing the data mining focus of IDS 572. In other words, you will get up to speed with the requisite background as well as the key theoretical underpinnings of modern analytics. We will do so through the lens of statistical machine learning. </p>
<h2>Previous Editions</h2>
<ul>
<li><a href="http://theja.org/teach/ids575s18.html">Spring 2018</a> (has videos!)</li>
<li><a href="http://theja.org/teach/ids575f17.html">Fall 2017</a> (has videos!)</li>
</ul>
<h2>Logistics</h2>
<ul>
<li>Lectures: Mondays 6.00 PM to 8.30 PM at BH 208</li>
<li>Optional Recitations: Thursdays 11 AM to 12 noon at BH 309</li>
<li>Staff<ul>
<li>Instructor: <a href="http://theja.org">Dr. Theja Tulabandhula</a> </li>
<li>Teaching Assistant: <a href="http://business.uic.edu/profiles/parshan-pakiman/">Parshan Pakiman</a></li>
</ul>
</li>
<li>Online communication: <a href="https://forum.chicagods.com">Forum</a> (sign up needed!)</li>
<li>Offline communication:<ul>
<li>Instructor Office Hours: Wednesdays 3.00 PM to 4.30 PM at UH 2404</li>
<li>TA Office Hours: Wednesdays 5 PM to 7 PM at UH2432</li>
</ul>
</li>
</ul>
<h2>Textbook and Materials</h2>
<ul>
<li>Textbook I: <a href="http://web.stanford.edu/~hastie/ElemStatLearn/">Elements of Statistical Learning II</a>.</li>
<li>Textbook II: <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a>.</li>
<li><a href="https://www.youtube.com/playlist?list=PLzq3B7Hh4uva2qkiTJHjWMkdg_Ng2KYgb">Refresher on probability</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLzq3B7Hh4uvZpOMDIpBWtOHsgnK0LLkJ-">Refresher on linear algebra</a></li>
</ul>
<h2>Software</h2>
<ul>
<li>The <a href="https://cran.r-project.org/index.html">R programming language</a> and the <a href="https://www.rstudio.com/">RStudio</a> IDE.</li>
</ul>
<h2>Schedule (<em>tentative</em>)</h2>
<h4>01/14 : Supervised Learning: Linear Models and Least Squares, k-Nearest Neighbor Methods</h4>
<ul>
<li><a href="https://chicagods.com/575/lec01.pdf">Lecture note</a></li>
<li><a href="https://chicagods.com/575/lec01_class.pdf">Handwritten note</a></li>
<li><a href="https://chicagods.com/575/Differences_with_572.pdf">Differences with Data Mining</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g1f88252dc4_0_203">Learning goal</a></li>
</ul>
<h4>01/28 : Towards Regression: Statistical Decision Theory, Curse of Dimensionality, Linear Regression, Categorical Variables, Interaction Terms</h4>
<ul>
<li><a href="https://chicagods.com/575/lec02.pdf">Lecture note</a></li>
<li><a href="https://chicagods.com/575/lec02_class.pdf">Handwritten note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g4e7831e39b_0_0">Learning goal</a></li>
</ul>
<h4>02/04 : Regression I: Bias-variance Trade-off, Subset Selection, Cross-Validation</h4>
<ul>
<li><a href="https://chicagods.com/575/lec03.pdf">Lecture note</a></li>
<li><a href="https://chicagods.com/575/lec03_class.pdf">Handwritten note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g4e15d95cce_0_0">Learning goal</a></li>
</ul>
<h4>02/11 : Regression II: Ridge Regression, LASSO (Least Absolute Shrinkage and Selection Operator)</h4>
<ul>
<li><a href="https://chicagods.com/575/lec04.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g4f8425003f_0_0">Learning goal</a></li>
<li><a href="https://github.com/dformoso/machine-learning-mindmap">Machine Learning Mindmap</a></li>
<li><a href="https://chicagods.com/575/Linear_Regression_Example.Rmd">Linear regression by gradient descent</a></li>
<li><a href="https://chicagods.com/575/lec04_class.pdf">Handwritten note</a></li>
</ul>
<h4>02/18 : Classification: Linear Discriminant Analysis, Logistic Regression, Model Assessment and Selection: AIC, BIC and Validation</h4>
<ul>
<li><a href="https://chicagods.com/575/lec05.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g4f8626be61_0_0">Learning goal</a></li>
<li><a href="https://chicagods.com/575/lec05_class.pdf">Handwritten note</a></li>
</ul>
<h4>02/25 : The Bootstrap, Maximum Likelihood Estimation and Review of Linear Models</h4>
<ul>
<li><a href="https://chicagods.com/575/lec06.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g506f952ebc_0_0">Learning goal</a></li>
<li><a href="https://chicagods.com/575/lec06_class.pdf">Handwritten note</a></li>
</ul>
<h4>03/11 : Expectation Maximization and Sampling (Markov Chain Monte Carlo)</h4>
<ul>
<li><a href="https://chicagods.com/575/lec07.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g5285723601_0_0">Learning goal</a></li>
<li><a href="https://chicagods.com/575/lec07_class.pdf">handwritten note</a></li>
</ul>
<h4>03/18 : Applications of regression, classification and likelihood maximization</h4>
<ul>
<li>Guest lecture by <a href="http://business.uic.edu/profiles/parshan-pakiman/">Parshan Pakiman</a></li>
<li><a href="https://chicagods.com/575/lec075_applications.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g5285723601_0_12">Learning goal</a></li>
</ul>
<h4>04/01 : Tree Methods, Adaboost and Gradient Boosting</h4>
<ul>
<li><a href="https://chicagods.com/575/lec08.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g5285723601_0_24">Learning goal</a></li>
</ul>
<h4>04/08 : Random Forests, Multivariate Adaptive Regression Splines and Support Vector Machines</h4>
<ul>
<li><a href="https://chicagods.com/575/lec09.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g5285723601_0_36">Learning goal</a></li>
</ul>
<h4>04/15 : Kernel Trick, Introduction to Unsupervised Learning, Association Rules</h4>
<ul>
<li><a href="https://chicagods.com/575/lec10.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g5285723601_0_48">Learning goal</a></li>
</ul>
<h4>04/22 : Unsupervised Learning: Clustering, Principal Component Analysis and Spectral Clustering</h4>
<ul>
<li><a href="https://chicagods.com/575/lec11.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g521eee7372_1_0">Learning goal</a></li>
</ul>
<h4>04/29 : Time Series and Supervised Learning, and the ARMA Model</h4>
<ul>
<li><a href="https://chicagods.com/575/lec12.pdf">Lecture note</a></li>
<li><a href="https://docs.google.com/presentation/d/1ZeFBD86iRE8-8JsqZX4YsqjsAP9R8ZaMreN2EM0ndq8/edit#slide=id.g521eee7372_1_12">Learning goal</a></li>
</ul>
<h2>Assignments</h2>
<ol>
<li>01/28: <a href="https://chicagods.com/575/assignment01.pdf">Assignment 1</a> out. Due on 02/10 </li>
<li>02/11: <a href="https://chicagods.com/575/assignment02.pdf">Assignment 2</a> out. Due on 02/24 </li>
<li>02/25: <a href="https://chicagods.com/575/assignment03.pdf">Assignment 3</a> out. Due on 03/17</li>
<li>04/01: <a href="https://chicagods.com/575/assignment04.pdf">Assignment 4</a> out. Due on 04/14</li>
<li>04/15: <a href="https://chicagods.com/575/assignment05.pdf">Assignment 5</a> out. Due on 04/28</li>
</ol>
<p>These involve reimplementing statistical techniques and understanding their behavior on interesting datasets. Always mention sources in your assignment solutions. Submission deadline is BEFORE 11.59 PM on the concerned day. Late submissions will have an automatic 20% penalty per day. Use <a href="https://uic.blackboard.com/">Blackboard</a> for uploads.</p>
<h2>Exams</h2>
<ol>
<li>03/04: Exam I (same venue as lectures, and during class hours)</li>
<li>05/06: Exam II (same venue as lectures, and during class hours)</li>
</ol>
<p>These are closed book, but one 8.5x11-inch handwritten cheatsheet is allowed.  No computers and communication devices are allowed.</p>
<h2>Grades</h2>
<ul>
<li>Assignments: 8% + 8% + 8% + 8% + 8% </li>
<li>Exams: 22% (Exam I) + 30% (Exam II)</li>
<li>Participation: 8% (online and offline)</li>
</ul>
<h2>Miscellaneous Information</h2>
<ul>
<li>This is a 4 credit graduate level course offered by the Information and Decision Sciences department at UIC.</li>
<li>Please see the <a href="http://catalog.uic.edu/ucat/academic-calendar/#2018-2019">academic calendar</a> for the semester timeline.</li>
<li>Students who wish to observe their religious holidays (http://oae.uic.edu/religious-calendar/) should notify the instructor within one week of the first lecture date. </li>
<li>Please contact the instructor at the earliest, if you require accommodations for access to and/or participation in this course.</li>
<li>Please refer to the academic integrity guidelines set by the university.</li>
</ul>

</article>

<footer> 
<small>If you see any errors, please contact the teaching staff.</small>
</footer>

	